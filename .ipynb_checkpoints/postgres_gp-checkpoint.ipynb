{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Creating-tables\" data-toc-modified-id=\"Creating-tables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Creating tables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-types-settings\" data-toc-modified-id=\"Data-types-settings-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data types settings</a></span></li><li><span><a href=\"#Loading-the-data-into-the-Postgres-table\" data-toc-modified-id=\"Loading-the-data-into-the-Postgres-table-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Loading the data into the Postgres table</a></span></li></ul></li><li><span><a href=\"#Setting-users-privileges\" data-toc-modified-id=\"Setting-users-privileges-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting users privileges</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-least-privilege-principle\" data-toc-modified-id=\"The-least-privilege-principle-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The least privilege principle</a></span></li><li><span><a href=\"#Testing-the-results\" data-toc-modified-id=\"Testing-the-results-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Testing the results</a></span></li></ul></li><li><span><a href=\"#Exploratory-Data-Analysis-(EDA)\" data-toc-modified-id=\"Exploratory-Data-Analysis-(EDA)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exploratory Data Analysis (EDA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-data-into-a-pandas-DataFrame\" data-toc-modified-id=\"Loading-the-data-into-a-pandas-DataFrame-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading the data into a pandas DataFrame</a></span></li><li><span><a href=\"#Quick-overview-with-raw-daily-data\" data-toc-modified-id=\"Quick-overview-with-raw-daily-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Quick overview with raw daily data</a></span></li><li><span><a href=\"#Zooming-on-UCR-Part-I-offenses\" data-toc-modified-id=\"Zooming-on-UCR-Part-I-offenses-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Zooming on UCR Part I offenses</a></span></li><li><span><a href=\"#Extracting-crime-trends-and-seasonality-with-Singular-Spectrum-Analysis-(SSA)\" data-toc-modified-id=\"Extracting-crime-trends-and-seasonality-with-Singular-Spectrum-Analysis-(SSA)-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Extracting crime trends and seasonality with Singular Spectrum Analysis (SSA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decomposition\" data-toc-modified-id=\"Decomposition-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Decomposition</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-trajectory-matrix\" data-toc-modified-id=\"The-trajectory-matrix-4.4.1.1\"><span class=\"toc-item-num\">4.4.1.1&nbsp;&nbsp;</span>The trajectory matrix</a></span></li><li><span><a href=\"#Singular-value-decompositon-(SVD)\" data-toc-modified-id=\"Singular-value-decompositon-(SVD)-4.4.1.2\"><span class=\"toc-item-num\">4.4.1.2&nbsp;&nbsp;</span>Singular value decompositon (SVD)</a></span></li><li><span><a href=\"#The-elementary-matrices\" data-toc-modified-id=\"The-elementary-matrices-4.4.1.3\"><span class=\"toc-item-num\">4.4.1.3&nbsp;&nbsp;</span>The elementary matrices</a></span></li><li><span><a href=\"#Diagonal-averaging\" data-toc-modified-id=\"Diagonal-averaging-4.4.1.4\"><span class=\"toc-item-num\">4.4.1.4&nbsp;&nbsp;</span>Diagonal averaging</a></span></li></ul></li><li><span><a href=\"#Plotting-the-components\" data-toc-modified-id=\"Plotting-the-components-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Plotting the components</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to build a Postgres database\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guided project, we will put everything together to build a database for storing data related with crimes that occurred in Boston. The cleaned dataset provided by [Dataquest](https://www.dataquest.io/) is available in the file <code>boston.csv</code>.\n",
    "\n",
    "The data we will work with is known as *Crime Incident Reports*. It's published under PDDL license by [Analyse Boston](https://data.boston.gov/). \n",
    "\n",
    "Crime incident reports are provided by Boston Police Department (BPD) to document the initial details surrounding an incident to which BPD officers respond. This is a dataset containing records from the new crime incident report system, which includes a reduced set of fields focused on capturing the type of incident as well as when and where it occurred. Records in the new system begin in June of 2015.\n",
    "\n",
    "More information and up-to-date Crime Incident Reports dataset can be found at: https://data.boston.gov/dataset/crime-incident-reports-august-2015-to-date-source-new-system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T07:26:57.534998Z",
     "start_time": "2020-10-01T07:26:56.732952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import psycopg2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T10:29:17.565778Z",
     "start_time": "2020-09-29T10:29:17.515778Z"
    }
   },
   "outputs": [],
   "source": [
    "#header and first four rows\n",
    "pd.read_csv('boston.csv')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column represents the identifier of the crime. The second contains a numeric identifier code for the committed crime. The third represents a description of the crime. The next two rows contain the date on which the crime happened and the corresponding day of the week. Finally, the last two columns represent the location of the crime with a latitude and longitude coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will create a database named <code>crimes_db</code> with a table – <code>boston_crimes</code> – with appropriate data types for storing the data. Then we will be creating the table inside a [schema](https://www.postgresql.org/docs/9.1/ddl-schemas.html) named <code>crimes</code>. We will also create the readonly and readwrite groups with the appropriate [privileges](https://www.postgresql.org/docs/9.1/ddl-priv.html). Finally, we will also need to create one user for each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connexion to the Dataquest database with user dq and new database creation\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"CREATE DATABASE crime_db;\"\"\")\n",
    "conn.autocommit = False #can we delete this line as we close the connexion just after?\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connexion to the new database and schema creation\n",
    "conn = psycopg2.connect(\"dbname=crime_db user=dq\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"CREATE SCHEMA crimes;\"\"\")\n",
    "conn.autocommit = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start creating tables, let's gather some data about our crime dataset so that we can more easily select the right data types to use in our tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the CSV file by using the csv module as follows:\n",
    "rows=list()\n",
    "with open('boston.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "col_headers = rows[0]\n",
    "first_row = rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the column names as well as the first row values at hand throughout this guided project so that we can easily take a look at them at any moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables\n",
    "### Data types settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, you may find useful to check the Postgres documentation for the following data types:\n",
    "* [Numeric Types](https://www.postgresql.org/docs/9.2/datatype-numeric.html)\n",
    "* [Character Types](https://www.postgresql.org/docs/9.2/datatype-character.html)\n",
    "* [Date/Time Types](https://www.postgresql.org/docs/9.2/datatype-datetime.html)\n",
    "* [Enumerated Types](https://www.postgresql.org/docs/9.2/datatype-enum.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify the proper data types for the columns. To help us with that, we will create a function — <code>get_col_value_set()</code> —  that given the name of a CSV file and a column index (starting at zero) computes a Python set with all distinct values contained in that column.\n",
    "This function will be useful for two reasons:\n",
    "* Checking whether an <code>enumerated</code> type might be a good choice for representing a column.\n",
    "* Computing the maximum length of any text-like column to select appropriate sizes for <code>varchar</code> columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_value_set(csv_filename, col_index):\n",
    "    with open(csv_filename, 'r') as f:\n",
    "        next(f) # skip the row containing column headers\n",
    "        reader = csv.reader(f)\n",
    "        # create a set to contain all distinct values contained in that column\n",
    "        unique_values_in_column = set()\n",
    "        for row in reader:\n",
    "            # add the column values from this row to the set\n",
    "            column_values = row[col_index]\n",
    "            unique_values_in_column.add(column_values)\n",
    "        return unique_values_in_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing with a for loop the number of unique values each column contains.\n",
    "for i in range(0,7):\n",
    "    print(col_headers[i],len(get_col_value_set('boston.csv', i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with a low number of distinct values tend to be good candidates for enumerated types.\n",
    "Another important aspect is to know the longest word in any column containing textual data. We can actually use the previous function for computing this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two textual column in the dataset, namely, the <code>description</code> and <code>day_of_the_week</code> columns. However the day of the week contains only $7$ different values, one for each day. We can tell that the longest of them is *Wednesday* without needing any computation.\n",
    "Let's compute the maximum length for the values contained in the description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description column index = 2\n",
    "description_values = get_col_value_set('boston.csv', 2)\n",
    "max_length = 0\n",
    "for row in description_values:\n",
    "    if len(row) > max_length:\n",
    "        max_length = len(row)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, according to Analyse Boston (see [Crime Incident Field Explanation](https://data.boston.gov/dataset/crime-incident-reports-august-2015-to-date-source-new-system/resource/9c30453a-fefa-4fe0-b51a-5fc09b0f4655)), the appropriate varchar length for this text field is $80$, so we will use this number when creating the table, as in the future we may want to update our database and new offense descriptions could arise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before examining the numerical columns, let's prepare the enumerated type query string for the weekday column. We will execute the query later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_type_string = \"\"\"CREATE TYPE day_of_the_week_enum AS ENUM\n",
    "    ('Sunday',\n",
    "     'Monday',\n",
    "     'Tuesday',\n",
    "     'Wednesday',\n",
    "     'Thursday',\n",
    "     'Friday',\n",
    "     'Saturday');\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column <code>incident_number</code> is an autoincrementing integer one. Since its maximum value ($=298329$) is only a $4$ bytes number, we will use the <code>serial</code> type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s retrieve the maximum value and the maximum length for the values contained in the second column <code>offense_code</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_code_values = get_col_value_set('boston.csv', 1)\n",
    "max_length = 0\n",
    "max_value = 0 \n",
    "for row in offense_code_values:\n",
    "    if len(row) > max_length:\n",
    "        max_length = len(row)\n",
    "    if int(row) > max_value:\n",
    "        max_value = int(row)\n",
    "print(max_length, max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the right data type for a given column may be a <code>character</code> type even if the values look like a number (as for postal codes for example). Here is one simple reason: you cannot perform arithmetic on them. In addition, leading zeros are important.\n",
    "In a SQL database, this would typically be <code>varchar</code> or <code>char</code>, of the appropriate length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth column contains the date when occurred the event, so we will use the <code>date</code> type which is used to represent a specific day of the year. The storage size fort this data type is $4$ bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the latitude and the longitude columns: they contains decimal numbers. With the Postgres <code>decimal</code> type, we can set our own precision and scale of the number which means we can choose how many bytes our entries will require.\n",
    "* The *precision* gives the maximum number of digits in total (before and after the decimal point). \n",
    "* The *scale* specifies the maximum amount of digits after the decimal point.\n",
    "\n",
    "As we already know the valid range in degrees for latitude ($-90°$ and $+90°$) as for longitude ($-180°$ and $+180°$), we just need to calculate the maximum scale contained in <code>lat</code> and <code>long</code> columns and then add $2$ for the latitude precision and $3$ for the longitude precision. By this way, our table will be correctly set in case of reuse with other location than Boston in the future.\n",
    "\n",
    "So we will create a function that computes the maximum scale for a given set of column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(col_value_set):    \n",
    "    max_scale = 0\n",
    "    for row in col_value_set:        \n",
    "        scale = 0\n",
    "        for idx, r in enumerate(row):            \n",
    "            if r == \".\":\n",
    "                scale = len(row)- idx - 1        \n",
    "        if scale > max_scale:\n",
    "            max_scale = scale\n",
    "    return(max_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_values = get_col_value_set('boston.csv', 5)\n",
    "long_values =  get_col_value_set('boston.csv', 6)\n",
    "lat_max_scale = get_scale(lat_values)\n",
    "long_max_scale = get_scale(long_values)\n",
    "print(lat_max_scale, long_max_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can create our table <code>boston_crimes</code> inside the <code>crimes</code> schema with the appropriate data type for each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executing the enumerated type query string\n",
    "cur.execute(create_type_string)\n",
    "#table creation query string\n",
    "create_string = \"\"\"CREATE TABLE crimes.boston_crimes (\n",
    "    incident_number serial PRIMARY KEY,\n",
    "    offense_code varchar(4),\n",
    "    description varchar(80),\n",
    "    date date,\n",
    "    day_of_the_week day_of_the_week_enum,\n",
    "    lat decimal(10,8),\n",
    "    long decimal(11,8)\n",
    " );\n",
    " \"\"\"\n",
    "#executing the table creation query string\n",
    "cur.execute(create_string)\n",
    "#commit the transaction\n",
    "conn.commit()\n",
    "#checking the result\n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes LIMIT 0;\")\n",
    "cur.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into the Postgres table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the table, we can load the data into it. We will use the [cursor.copy_expert() method](https://www.psycopg.org/docs/cursor.html#cursor.copy_expert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"boston.csv\") as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "conn.commit()\n",
    "#checking the result printing the first five rows\n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes LIMIT 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting users privileges\n",
    "### The least privilege principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the [least privilege principle](https://en.wikipedia.org/wiki/Principle_of_least_privilege), the first step in doing so is to make sure that there are no privileges inherited from the <code>public</code> group and on the <code>public</code> schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"REVOKE ALL ON SCHEMA public FROM public;\"\"\")\n",
    "cur.execute(\"\"\"REVOKE ALL ON DATABASE crime_db FROM public;\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *readonly* group is defined as a users group who has no other privileges except for being able to read data from your database. This is likely the type of users profile that we would set up for **data analysts** as, in general, such users need only to be able to access the data for analysis. So we will only grant <code>SELECT</code> privileges for the readonly group.\n",
    "\n",
    "Another common group is the *readwrite* group which has privileges to read, insert and remove data from tables but cannot drop tables. In a similar way, you can think of the readwrite to be a suitable group for **data scientists**. Those users need to be able to analyze the data but they are also responsible for collecting, cleaning the data and loading it into the database.\n",
    "Following the least privilege principle, it seems that a suitable set of privileges for these kinds of users consist of the <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code> and <code>DELETE</code> commands.\n",
    "\n",
    "The <code>DROP</code> commands that is used to remove a table is not usually granted as it is more of a **data engineer** role to setup the platform and deal with table creation as with data types settings.\n",
    "\n",
    "These roles are of course not mutually exclusive and can share common tasks.\n",
    "However these user groups are quite common as you can read in this [blog post]( https://aws.amazon.com/es/blogs/database/managing-postgresql-users-and-roles/).\n",
    "\n",
    "It's also a good practice to always make sure that groups cannot be used for login. We can do that using the <code>NOLOGIN</code> option when creating the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two groups named readonly and readwrite with the no NOLOGIN option.\n",
    "cur.execute(\"\"\"CREATE GROUP readonly NOLOGIN;\"\"\")\n",
    "cur.execute(\"\"\"CREATE GROUP readwrite NOLOGIN;\"\"\")\n",
    "#the two groups need connection privileges, otherwise they won't be able to do anything\n",
    "cur.execute(\"\"\"GRANT CONNECT ON DATABASE crime_db TO readonly;\"\"\")\n",
    "cur.execute(\"\"\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\"\"\")\n",
    "#they also need usage privileges for the crimes schema\n",
    "cur.execute(\"\"\"GRANT USAGE ON SCHEMA crimes TO readonly;\"\"\")\n",
    "cur.execute(\"\"\"GRANT USAGE ON SCHEMA crimes TO readwrite;\"\"\")\n",
    "#setting specific privileges to each group for all tables in crimes schema\n",
    "cur.execute(\"\"\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\"\"\")\n",
    "cur.execute(\"\"\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step, we will create one user with password for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"CREATE USER data_analyst WITH PASSWORD 'secret1';\"\"\")\n",
    "cur.execute(\"\"\"GRANT data_analyst TO readonly;\"\"\")\n",
    "cur.execute(\"\"\"CREATE USER data_scientist WITH PASSWORD 'secret2';\"\"\")\n",
    "cur.execute(\"\"\"GRANT data_scientist TO readwrite;\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to test that everything is configured as expected when you finish setting up the database. \n",
    "We can use SQL queries to check whether the objects have been created and that users and groups have the right privileges. This requires you to know the Postgres internal tables. We can query the [pg_roles table](https://www.postgresql.org/docs/10/view-pg-roles.html) to inspect privileges related to the database and the [information_schema.table_privileges table](https://www.postgresql.org/docs/9.1/infoschema-table-privileges.html) to inspect table privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee = 'readwrite';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee = 'readonly';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT rolsuper, rolcanlogin, rolcreaterole, rolcreatedb\n",
    "    FROM pg_roles\n",
    "    WHERE rolname = 'readonly';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT rolsuper, rolcanlogin, rolcreaterole, rolcreatedb\n",
    "    FROM pg_roles\n",
    "    WHERE rolname = 'readwrite';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT rolsuper, rolcanlogin, rolcreaterole, rolcreatedb, rolpassword\n",
    "    FROM pg_roles\n",
    "    WHERE rolname = 'data_analyst';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT rolsuper, rolcanlogin, rolcreaterole, rolcreatedb, rolpassword\n",
    "    FROM pg_roles\n",
    "    WHERE rolname = 'data_scientist';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"SELECT rolsuper, rolcanlogin, rolcreaterole, rolcreatedb, rolpassword\n",
    "    FROM pg_roles\n",
    "    WHERE rolname = 'dq';\"\"\"\n",
    "cur.execute(test_string)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After <code>cheking pg_roles</code> and <code>information_schema.table_privileges</code> tables, it appears that:\n",
    "* Table privileges are correctly granted for each group.\n",
    "* Database privileges have been correctly limited for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T07:29:19.532119Z",
     "start_time": "2020-10-01T07:29:19.476116Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_metadata": {
   "author": "WilfridF",
   "title": "Boston Crimes Report"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
